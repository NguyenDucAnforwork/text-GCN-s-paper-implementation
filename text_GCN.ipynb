{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKayDC-1ivYl",
        "outputId": "3597c59b-dbe9-46e2-f95a-1b3aa7dc2ae7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "4VlfVMNb9syz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kUYdoGNU9b25"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import to_dense_adj, to_networkx\n",
        "from torch_geometric.datasets import KarateClub\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import csv\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "import torch.nn.functional as F\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Tách từ và loại bỏ các từ dừng\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text.lower())  # Chuyển đổi văn bản thành chữ thường và tách từ\n",
        "    tokens = [token for token in tokens if token.isalpha()]  # Loại bỏ các ký tự không phải chữ cái\n",
        "    tokens = [token for token in tokens if token not in stopwords.words('english')]  # Loại bỏ các từ dừng\n",
        "    tokens = [token for token in tokens if token in filtered_words]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "VTeWlpuA5r1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22986045-129c-407f-dfbc-a87e60240315"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datapath = \"./data.csv\"\n",
        "with open(datapath, \"r\") as csv_file:\n",
        "  reader = csv.reader(csv_file, quotechar='\"')\n",
        "  documents, labels = [], []\n",
        "  for idx, line in enumerate(reader):\n",
        "    if idx > 0:\n",
        "      documents.append(line[0])\n",
        "      labels.append(line[1])"
      ],
      "metadata": {
        "id": "hH0AaXvNjGQ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_words(documents, min_count):\n",
        "    # Tạo từ điển stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Tính toán số lần xuất hiện của từng từ trong documents\n",
        "    word_counts = Counter()\n",
        "    for doc in documents:\n",
        "        words = word_tokenize(doc.lower())\n",
        "        # Loại bỏ stop words và các ký tự không phải chữ cái\n",
        "        words = [word for word in words if word.isalpha() and word not in stop_words]\n",
        "        word_counts.update(words)\n",
        "    # Loại bỏ các từ xuất hiện dưới ngưỡng và stop words\n",
        "    filtered_words = {word: count for word, count in word_counts.items() if count >= min_count}\n",
        "    return filtered_words\n",
        "\n",
        "# Sử dụng hàm filter_words để lọc ra từ điển các từ còn lại\n",
        "filtered_words = filter_words(documents, 5)\n"
      ],
      "metadata": {
        "id": "7rRhS6_q61w7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, word in enumerate(filtered_words):\n",
        "  print(idx, word)"
      ],
      "metadata": {
        "id": "S6aBJvLBcbUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for doc in documents:\n",
        "  a = tokenize_text(doc)\n",
        "  b = \" \".join(a)\n",
        "  docs.append(b)"
      ],
      "metadata": {
        "id": "zfJyUIZ6WEAE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(math.log(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl97TTlCiZUN",
        "outputId": "3f3fd5d0-f7c6-479c-ab2c-5428cb21cb24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.302585092994046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf(word, document, docs):\n",
        "  num_word = document.count(word)\n",
        "  tf = num_word / len(tokenize_text(document))\n",
        "\n",
        "  num_doc = 0\n",
        "  for doc in docs:\n",
        "    if word in doc:\n",
        "      num_doc += 1\n",
        "  idf = (math.log( (len(docs) + 1) / (num_doc + 1))) + 1\n",
        "\n",
        "  return tf * idf"
      ],
      "metadata": {
        "id": "rnYt-SilVtuX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_words, num_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9IpTAf7kQKI",
        "outputId": "8b8e5129-3e37-4346-ccbf-2eeff39b9622"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf(indices[34], indices[36], docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08XnxButXAmw",
        "outputId": "78b8c130-0584-45fb-d026-3581836e8238"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6756876285817388"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Tập hợp các văn bản đầu vào\n",
        "\n",
        "# Khởi tạo TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Tính toán ma trận TF-IDF cho toàn bộ tập văn bản\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Lấy danh sách các từ vựng (unique words)\n",
        "unique_words = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Xác định chỉ số của từ \"reviewers\" trong danh sách các từ vựng\n",
        "word_index = unique_words.tolist().index(\"one\")\n",
        "print(word_index)\n",
        "# Lấy chỉ số TF-IDF của từ \"reviewers\" trong văn bản đầu tiên\n",
        "tfidf_score = tfidf_matrix[0, word_index]\n",
        "\n",
        "print(\"TF-IDF score của từ 'reviewers' trong văn bản đầu tiên:\", tfidf_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGRFhDR5q6AR",
        "outputId": "1d9634e5-58b5-456d-9ec0-8fc3d33b315d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638\n",
            "TF-IDF score của từ 'reviewers' trong văn bản đầu tiên: 0.03131539805774427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmxdMo5JWuH_",
        "outputId": "462822c1-f3e2-458f-8ecd-fe661e73dc00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one watching oz right br br first oz scenes right go show show br br oz many never far br br would say show would pretty oz first say oz well watching oz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(filtered_words)\n",
        "num_documents = len(docs)\n",
        "\n",
        "indices = {idx: word for idx, word in enumerate(filtered_words)}\n",
        "for idx, doc in enumerate(docs):\n",
        "  indices[idx + num_words] = doc"
      ],
      "metadata": {
        "id": "aTusgipJJOvm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(indices[638])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZB0_WSRcN17",
        "outputId": "b20d51ce-466c-44d4-c277-dc70082d8d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atmosphere\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Khởi tạo ma trận one-hot encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Chuẩn bị dữ liệu đầu vào cho one-hot encoding\n",
        "data = np.array(list(indices.values())).reshape(-1, 1)\n",
        "\n",
        "# Thực hiện one-hot encoding\n",
        "X = encoder.fit_transform(data)\n",
        "\n",
        "# In kích thước của ma trận one-hot encoded\n",
        "print(\"Kích thước của ma trận one-hot encoded:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc9Hi1HbSpYC",
        "outputId": "c3427c24-4f63-472c-81e6-f8c36db4b33e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kích thước của ma trận one-hot encoded: (56, 56)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = unique_words.tolist().index(\"one\")\n",
        "print(word_index)"
      ],
      "metadata": {
        "id": "afjIFolXgK_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Khai báo kích thước cố định của sliding window\n",
        "fixed_size = 5\n",
        "\n",
        "\n",
        "# Khởi tạo từ điển sliding_window\n",
        "sliding_windows = {}\n",
        "\n",
        "# Lặp qua mỗi từ trong documents\n",
        "for doc in documents:\n",
        "    words = doc.split()\n",
        "    # Lặp qua mỗi từ trong văn bản\n",
        "    for i in range(len(words) - fixed_size):\n",
        "      window = words[i:i+fixed_size]\n",
        "      for word in window:\n",
        "        if word in filtered_words:\n",
        "          if word not in sliding_windows:\n",
        "            sliding_windows[word] = 0\n",
        "          sliding_windows[word] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "0BBvHM274JOo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In kết quả\n",
        "for word, count in sliding_windows.items():\n",
        "    print(\"Word:\", word)\n",
        "    print(\"Number of sliding windows containing this word:\", count)"
      ],
      "metadata": {
        "id": "PDxe8T48Vsr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo mảng W\n",
        "W = {}\n",
        "\n",
        "# Khai báo kích thước cố định của sliding window\n",
        "fixed_size = 5\n",
        "\n",
        "# Lặp qua mỗi văn bản trong documents\n",
        "for doc in documents:\n",
        "    words = tokenize_text(doc)\n",
        "    # Tạo set từ vựng cho mỗi văn bản để kiểm tra sự xuất hiện của từng từ\n",
        "    # Lặp qua từng từ trong filtered_words\n",
        "    for i in range(len(words) - fixed_size):\n",
        "      windows = words[i:i+fixed_size]\n",
        "      for j in range(len(windows)):\n",
        "        for k in range(j):\n",
        "          pair = (words[j], words[k]) if words[j] > words[k] else (words[k], words[j])\n",
        "          if pair not in W:\n",
        "            W[pair] = 0\n",
        "          W[pair] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "8twrMzx874FL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In kết quả\n",
        "for key, value in W.items():\n",
        "    print(\"Words:\", key)\n",
        "    print(\"Number of windows containing both words:\", value)"
      ],
      "metadata": {
        "id": "zLPWRgGzJshX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(indices[1200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mi1c0-cfvM7",
        "outputId": "5dd0ae1d-a9db-4bde-fa1c-912f04b7d4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "originally fan first rather disappointed watching movie view changed movie pretty funny beginning end found even though really stupid storyline portray movie br br much entertaining enjoyable movies seen saw dull way really enjoyed br br enjoyed enjoy band earth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = [[0 for i in range(num_words + num_documents)] for j in range(num_words + num_documents)]\n",
        "window_size = sum([len(doc.split()) - 2 for doc in docs])\n",
        "\n",
        "for i in range(num_words + num_documents):\n",
        "  for j in range(i, num_words + num_documents):\n",
        "    if i == j:\n",
        "      A[i][j] = 1\n",
        "    elif(i < num_words) and j < num_words:\n",
        "      pair = (indices[i], indices[j]) if indices[i] < indices[j] else (indices[j], indices[i])\n",
        "      A[i][j] = window_size * W[pair] / \\\n",
        "                  sliding_windows[indices[i]] / sliding_windows[indices[j]] if pair in W else 0\n",
        "    elif i < num_words and j >= num_words:\n",
        "      # if indices[i] in unique_words.tolist():\n",
        "      #   word_index = unique_words.tolist().index((indices[i]))\n",
        "        # print(word_index, indices[i])\n",
        "        # Lấy chỉ số TF-IDF của từ \"reviewers\" trong văn bản đầu tiên\n",
        "        # print(j-num_words, word_index)\n",
        "        tfidf_score = tfidf(indices[i], indices[j], docs)\n",
        "        print(tfidf_score)\n",
        "        if tfidf_score > 0:\n",
        "          A[i][j] = tfidf_score\n",
        "    else:\n",
        "      A[i][j] = 0\n",
        "    A[j][i] = A[i][j]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "su_65K1VTVNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(A)\n",
        "zero_ratio = np.mean(arr == 0)\n",
        "print(zero_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CprFQTGM40sm",
        "outputId": "b796652d-035b-46a0-bbb2-0e4d0113ecf8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8596938775510204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = [[0 for i in range(num_words + num_documents)] for j in range(num_words + num_documents)]\n",
        "for i in range(num_words + num_documents):\n",
        "  D[i][i] = sum([A[i][j] for j in range(num_words + num_documents)])"
      ],
      "metadata": {
        "id": "BkmbGPTF9MhE"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor(A)\n",
        "D = torch.tensor(D)\n",
        "X = torch.tensor(X)"
      ],
      "metadata": {
        "id": "TW8yt2Xn9oiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c32d52-4ed5-4f6c-bfba-dbce21df6585"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-7730f115e656>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X = torch.tensor(X)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxYOlEww9ttd",
        "outputId": "d4698f54-2c49-4365-d1de-16417fcef3fb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.9156, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 1.6303, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 1.6093,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 2.7415, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 2.7858, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 3.2250]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGCN(nn.Module):\n",
        "  def __init__(self, A, D, vocab_size, num_outputs, num_labels):\n",
        "    super().__init__()\n",
        "    self.A = A\n",
        "    self.D = D\n",
        "    self.vocab_size = vocab_size\n",
        "    self.num_outputs = num_outputs\n",
        "    self.A_ = torch.matmul(torch.matmul(torch.inverse(torch.sqrt(D)), A), torch.inverse(torch.sqrt(D)))\n",
        "    self.layer1 = nn.Linear(vocab_size, num_outputs)\n",
        "    self.layer2 = nn.Linear(num_outputs, num_labels)\n",
        "  def forward(self, X):\n",
        "    layer1 = self.layer1(torch.matmul(self.A_.float(), X.float()))\n",
        "    out = F.relu(layer1)\n",
        "    layer2 = self.layer2(torch.matmul(self.A_, out))\n",
        "    output = F.softmax(layer2)\n",
        "    return output"
      ],
      "metadata": {
        "id": "KZpFExhH91QS"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = num_words + num_documents\n",
        "gcn = TextGCN(A, D, vocab_size, 10, 2)\n",
        "output = gcn(X)"
      ],
      "metadata": {
        "id": "GFMaeDjICShn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594a27ca-fbfb-4909-965a-42b7e15639b8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-7e1441e45da3>:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  output = F.softmax(layer2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bekDTQD5isAq",
        "outputId": "91a4f70d-bab5-4d38-c0c9-a0aaf0956df7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5879, 0.4121],\n",
            "        [0.5891, 0.4109],\n",
            "        [0.5980, 0.4020],\n",
            "        [0.5954, 0.4046],\n",
            "        [0.5890, 0.4110],\n",
            "        [0.5901, 0.4099],\n",
            "        [0.5909, 0.4091],\n",
            "        [0.5941, 0.4059],\n",
            "        [0.5966, 0.4034],\n",
            "        [0.5936, 0.4064],\n",
            "        [0.5919, 0.4081],\n",
            "        [0.5929, 0.4071],\n",
            "        [0.5923, 0.4077],\n",
            "        [0.5862, 0.4138],\n",
            "        [0.5964, 0.4036],\n",
            "        [0.5865, 0.4135],\n",
            "        [0.5899, 0.4101],\n",
            "        [0.5894, 0.4106],\n",
            "        [0.5932, 0.4068],\n",
            "        [0.5926, 0.4074],\n",
            "        [0.5881, 0.4119],\n",
            "        [0.5917, 0.4083],\n",
            "        [0.5870, 0.4130],\n",
            "        [0.5901, 0.4099],\n",
            "        [0.5890, 0.4110],\n",
            "        [0.5897, 0.4103],\n",
            "        [0.5833, 0.4167],\n",
            "        [0.5914, 0.4086],\n",
            "        [0.5948, 0.4052],\n",
            "        [0.5916, 0.4084],\n",
            "        [0.5902, 0.4098],\n",
            "        [0.5945, 0.4055],\n",
            "        [0.5922, 0.4078],\n",
            "        [0.5860, 0.4140],\n",
            "        [0.5984, 0.4016],\n",
            "        [0.5913, 0.4087],\n",
            "        [0.5960, 0.4040],\n",
            "        [0.5863, 0.4137],\n",
            "        [0.5903, 0.4097],\n",
            "        [0.5897, 0.4103],\n",
            "        [0.5894, 0.4106],\n",
            "        [0.5902, 0.4098],\n",
            "        [0.5923, 0.4077],\n",
            "        [0.5958, 0.4042],\n",
            "        [0.5882, 0.4118],\n",
            "        [0.5892, 0.4108],\n",
            "        [0.5904, 0.4096],\n",
            "        [0.5892, 0.4108],\n",
            "        [0.5940, 0.4060],\n",
            "        [0.5907, 0.4093],\n",
            "        [0.5942, 0.4058],\n",
            "        [0.5920, 0.4080],\n",
            "        [0.5882, 0.4118],\n",
            "        [0.5874, 0.4126],\n",
            "        [0.5856, 0.4144],\n",
            "        [0.5917, 0.4083]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CtkMF0SmbSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}